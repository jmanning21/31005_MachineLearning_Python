{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmanning21/31005_MachineLearning_Python/blob/master/Machine_Learning_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDh23ZzhcyU",
        "colab_type": "text"
      },
      "source": [
        "#Assignment 2: Practical Machine Learning Project\n",
        "####Affnan Amir (13528841) and Julia Manning (12875795)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjezS5t_-Gzl",
        "colab_type": "text"
      },
      "source": [
        "###Introduction\n",
        "The algorithm chosen for this project is the ID3 Decision Tree building algorithm. In using this alrogithm, the data  \n",
        "\n",
        "* Input = titanic dataset from given url:\n",
        "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
        "* Output = predicted resutls for those individuals which survived (i.e. binary options; Did they survive? Yes or No)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqiTYMTfEyE7",
        "colab_type": "text"
      },
      "source": [
        "###Exploration\n",
        "\n",
        "Challenges:\n",
        " - over-fitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBDy0_3aE2so",
        "colab_type": "text"
      },
      "source": [
        "###Methodology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_GJFfN7QGa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the required packages\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4CofyopSsOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the dataset from a url\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "# Read the csv and convert to a dataframe\n",
        "d = pd.read_csv(url)\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "# See the first six rows of the dataset\n",
        "df.head(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Mfq1ipUo65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning some of the attributes: replace null values with median values\n",
        "# Replacing NA values in age with the median age of each sex\n",
        "median_values = df.groupby('Sex')['Age'].transform('median')\n",
        "df['Age'].fillna(median_values, inplace=True)\n",
        "df.head(6) # see the first 6 rows to see if the NA value was replaced in Ln 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaDbdlQLsSFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the information about the dataset\n",
        "df.info()\n",
        "# There are no missing values in the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UAtAW8Ynitk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identify the target variable\n",
        "df['Survived'],class_names = pd.factorize(df['Survived'])\n",
        "\n",
        "print(class_names)\n",
        "print(df['Survived'].unique())\n",
        "\n",
        "# The algorithm requires the target variable to be in integer format, which it already is. \n",
        "# Therefore no data type changes need to be made."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_OqwSbp2Ksy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding and removing specific columns which may help with the accuracy of the accuracy.\n",
        "# Add a Child.Adult column based on the age of the individual\n",
        "df['Child.Adult'] = 'Adult'\n",
        "\n",
        "# Child = Age < 13 and Adult = Age >= 13 \n",
        "df['Child.Adult'][df['Age'] < 13.0] = 'Child'\n",
        "\n",
        "# Remove 'Name' column as it does not provide any relevant information to the dataset, as all the values are unique\n",
        "del df['Name']\n",
        "# Remove 'Cabin' as there are too many NA values and the remaining values are all unique, make it impossible to determine a suitable replacement for the NA values\n",
        "del df['Cabin']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIFwjwXoub5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identifying the predictor variables and encode any string variables to their equivalent integer formats\n",
        "df['Sex'],_ = pd.factorize(df['Sex'])\n",
        "df['Embarked'],_ = pd.factorize(df['Embarked'])\n",
        "df['Child.Adult'],_ = pd.factorize(df['Child.Adult'])\n",
        "df['Ticket'],_ = pd.factorize(df['Ticket'])\n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjE-8XBlyh6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-ordering the columns to put the 'Survived' column last\n",
        "df = df[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Ticket','Fare','Embarked','Child.Adult','Survived']]\n",
        "df.head(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCxHtlc17Dbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selecting the predictor feature and target variable\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NeRC-Gp7Rw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data randomly into 60% training and 40% test\n",
        "train_data_split = 0.6 #@param {type:\"number\", min:0.01, max:0.99}\n",
        "test_data_split = 1 - train_data_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_data_split, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyPvRDAFpDw5",
        "colab_type": "code",
        "outputId": "dc713f5f-aae1-4421-e180-21d76e253e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# training/model fitting\n",
        "# train the decision tree\n",
        "dtree = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 5, random_state = 0)\n",
        "dtree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort=False,\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rKFJy-Mpz5T",
        "colab_type": "code",
        "outputId": "c7d53958-9711-4f9b-d3b2-e001ff294f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# use model to make predictions with \n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "# see how good the model performs\n",
        "misclassified_count = (y_test != y_pred).sum()\n",
        "print('Misclassified samples: {}'.format(misclassified_count))\n",
        "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "print('Accuracy: {:.4f}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified samples: 77\n",
            "Accuracy: 0.7843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5b_yI15si8f",
        "colab_type": "text"
      },
      "source": [
        "###Alternate way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN1ZCy7rspT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPfS2i6js174",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function importing dataset and cleaning\n",
        "def importdata(): \n",
        "  url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "  # Read the csv and convert to a dataframe\n",
        "  d = pd.read_csv(url)\n",
        "  df = pd.DataFrame(data=d)\n",
        "\n",
        "  # See the first six rows of the dataset\n",
        "  df.head(6)\n",
        "\n",
        "  # Adding and removing specific columns which may help with the accuracy of the accuracy.\n",
        "  # Add a Child.Adult column based on the age of the individual\n",
        "  df['Child.Adult'] = 'Adult'\n",
        "\n",
        "  # Child = Age < 13 and Adult = Age >= 13 \n",
        "  df['Child.Adult'][df['Age'] < 13.0] = 'Child'\n",
        "\n",
        "  # Remove 'Name' column as it does not provide any relevant information to the dataset, as all the values are unique\n",
        "  del df['Name']\n",
        "  # Remove 'Cabin' as there are too many NA values and the remaining values are all unique, make it impossible to determine a suitable replacement for the NA values\n",
        "  del df['Cabin']\n",
        "\n",
        "  # Re-ordering the columns to put the 'Survived' column last\n",
        "  df = df[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Ticket','Fare','Embarked','Child.Adult','Survived']]\n",
        "  \n",
        "  df['Sex'],_ = pd.factorize(df['Sex'])\n",
        "  df['Embarked'],_ = pd.factorize(df['Embarked'])\n",
        "  df['Child.Adult'],_ = pd.factorize(df['Child.Adult'])\n",
        "  df['Ticket'],_ = pd.factorize(df['Ticket'])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYcfqxjGtSPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to split the data\n",
        "def splitdataset(df,split):\n",
        "  # Seperating the target variable \n",
        "    X = df.iloc[:,:-1]\n",
        "    Y = df.iloc[:,-1] \n",
        "    test_split = 1 - split\n",
        "    \n",
        "    # Spliting the dataset into train and test \n",
        "    X_train, X_test, y_train, y_test = train_test_split(  \n",
        "    X, Y, test_size = test_split, random_state = 100) \n",
        "    \n",
        "    return X, Y, X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41lq8d5MwICu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to perform training with giniIndex. \n",
        "def train_using_gini(X_train, X_test, y_train): \n",
        "  \n",
        "    # Creating the classifier object \n",
        "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
        "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_gini.fit(X_train, y_train) \n",
        "    return clf_gini "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcBy3wBnwIBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to perform training with entropy. \n",
        "def train_using_entropy(X_train, X_test, y_train): \n",
        "  \n",
        "    # Decision tree with entropy \n",
        "    clf_entropy = DecisionTreeClassifier( \n",
        "            criterion = \"entropy\", random_state = 100, \n",
        "            max_depth = 3, min_samples_leaf = 5) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_entropy.fit(X_train, y_train) \n",
        "    return clf_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUB60GLYwIAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to make predictions \n",
        "def prediction(X_test, clf_object): \n",
        "  \n",
        "    # Predicton on test with giniIndex \n",
        "    y_pred = clf_object.predict(X_test) \n",
        "    print(\"Predicted values:\") \n",
        "    print(y_pred) \n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIw34vaHwd-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate accuracy \n",
        "def cal_accuracy(y_test, y_pred): \n",
        "      \n",
        "    print(\"Confusion Matrix: \", \n",
        "        confusion_matrix(y_test, y_pred)) \n",
        "      \n",
        "    print (\"Accuracy : \", \n",
        "    accuracy_score(y_test,y_pred)*100) \n",
        "      \n",
        "    print(\"Report : \", \n",
        "    classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9XUebg1wntb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Driver code \n",
        "def main(): \n",
        "      \n",
        "    # Building Phase \n",
        "    data = importdata()\n",
        "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data,var) \n",
        "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
        "    clf_entropy = train_using_entropy(X_train, X_test, y_train) \n",
        "      \n",
        "    # Operational Phase \n",
        "    print(\"Results Using Gini Index:\") \n",
        "      \n",
        "    # Prediction using gini \n",
        "    y_pred_gini = prediction(X_test, clf_gini) \n",
        "    cal_accuracy(y_test, y_pred_gini) \n",
        "      \n",
        "    print(\"Results Using Entropy:\") \n",
        "    # Prediction using entropy \n",
        "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
        "    cal_accuracy(y_test, y_pred_entropy) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWY99ANawsWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "bf9cb530-4105-4e4a-fc62-1dbd758aa6a6"
      },
      "source": [
        "# Run the entire code\n",
        "var = float(input(\"Enter the training data split number: \"))\n",
        "if type(var) is float:\n",
        "  main()\n",
        "else:\n",
        "  print(\"\")\n",
        "  print(\"Enter a number between 0.01 and 0.99\")\n",
        "  var = input(\"Enter the training data split number: \")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the training data split number: 0.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a8b618bb73e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the training data split number: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-5f0c2440aa23>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf_gini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_using_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclf_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_using_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-4f7f5afd8cf6>\u001b[0m in \u001b[0;36mtrain_using_gini\u001b[0;34m(X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Performing training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf_gini\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf_gini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQuWKfGWE5RN",
        "colab_type": "text"
      },
      "source": [
        "###Evaluation\n",
        "Improvements for future renditions: \n",
        "- When producing the ages for null values in the dataset, the ages could have been grouped by class and gender of the individual, rather than just using gender. This may produce a more accurate number. The age range for females is: 0.75-63, giving a range difference of 62.25, whilst the age range for males is: 0.42-80, giving a age range of 79.58. The age range is also specified further when Pclass is added.\n",
        "- Use Gini Idex instead of Entropy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHQsYEjgDbE2",
        "colab_type": "text"
      },
      "source": [
        "###Results\n",
        "This is the results from the decision tree model, displaying the accuracy outcomes for the changing variables\n",
        "\n",
        "Train Data Split|Criterion|Max Depth|Misclassified|Accuracy\n",
        "---|---|---|---|---\n",
        "0.6|Entropy|3|70|0.8039\n",
        "0.6|Entropy|5|68|0.8095\n",
        "0.6|Gini|3|67|0.8123\n",
        "0.6|Gini|5|77|0.7843\n",
        "0.7|Entropy|3|48|0.8209\n",
        "0.7|Entropy|5|48|0.8209\n",
        "0.7|Gini|3|48|0.8209\n",
        "0.7|Gini|5|49|0.8172"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb1GeQENE8Jj",
        "colab_type": "text"
      },
      "source": [
        "###Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoVVVg29E-B2",
        "colab_type": "text"
      },
      "source": [
        "###Ethical Justification\n",
        "\n",
        "- potential misuses of the technique\n",
        "- utilitarian view?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5QikhaZFA0x",
        "colab_type": "text"
      },
      "source": [
        "###Video Pitch\n",
        "*Attached to the final document*"
      ]
    }
  ]
}